{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 此样例联系模型的存储和读取\n",
    "## 输入\n",
    "x1, x2\n",
    "## 输出\n",
    "y = x1 + x2 >= 0? 1: 0;\n",
    "## 实现方法\n",
    "自定义模块，继承`torch.nn.Module`并定义`forward`函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生数据\n",
    "使用`torch.randn()`随机生成满足标准正态分布的张量，size为$1000\\times2$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1000, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用`torch.sum(input, dim, keepdim=False, dtype=None)`生成label，其参数如下：\n",
    "* `input`：需要求和的tensor\n",
    "* `dim`：需要求和的维度\n",
    "* `keepdim`：默认为False，如果为True则求和后的输出的维数与input相同\n",
    "\n",
    "也可以使用`y[x.sum(dim=1) >= 0] = 1`生成label。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = torch.zeros(1000, 1)\n",
    "y[torch.sum(x, dim=1) >= 0] = 1\n",
    "# y[x.sum(dim=1) >= 0] = 1\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型并训练\n",
    "### 建立网络\n",
    "自定义模块，继承`torch.nn.Module`并定义`forward`函数。\n",
    "\n",
    "也可以通过控制流（循环语句）重复使用相同模块（如某一隐藏层）。\n",
    "```python\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.h = torch.nn.Linear(H, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        relu = self.relu(self.linear1(x))\n",
    "        for _ in range(3):\n",
    "            relu = self.relu(self.h(relu))\n",
    "        y_pred = self.sigmoid(self.linear2(relu))\n",
    "        return y_pred\n",
    "```\n",
    "可以通过`list(model.parameters())[index]`查看对应层的参数，其中重复使用的模块权值共享。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        relu = self.relu(self.linear1(x))\n",
    "        y_pred = self.sigmoid(self.linear2(relu))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数\n",
    "损失函数使用`torch.nn.BCELoss()`，即Binary Cross Entrophy Loss，适用于使用Sigmoid激活函数的二分类问题。\n",
    "* `input`: Tensor of arbitrary shape\n",
    "* `target`: Tensor of the same shape as input\n",
    "\n",
    "### 优化器\n",
    "使用`torch.optim.Adam()`进行梯度下降，其重要的参数为：\n",
    "* `params`：网络的权重，通过`model.parameters()`获取，为可迭代类型\n",
    "* `lr`：学习率learning_rate，默认为1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoLayerNet(2, 4, 1)\n",
    "learning_rate = 1e-3\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自动求导\n",
    "* `optimizer.zero_grad()`：在反向传播之前，使用optimizer将它要更新的所有张量的梯度清零(这些张量是模型可学习的权重)\n",
    "* `loss.backward()`：反向传播：根据模型的参数计算loss的梯度\n",
    "* `optimizer.step()`：调用Optimizer的step函数使它所有参数更新\n",
    "\n",
    "也可将以上三条语句替换为以下代码：\n",
    "```python\n",
    "# 反向传播之前清零梯度\n",
    "model.zero_grad()\n",
    "loss.backward()\n",
    "# 使用梯度下降更新权重。\n",
    "# 每个参数都是张量，所以我们可以像我们以前那样可以得到它的数值和梯度\n",
    "with torch.no_grad():\n",
    "    for param in model.parameters():\n",
    "        param -= learning_rate * param.grad\n",
    "```\n",
    "此时不使用优化器，而是在`torch.no_grad()`上下文环境中更新梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7108566761016846\n",
      "1 0.7098792791366577\n",
      "2 0.7089057564735413\n",
      "3 0.7079359292984009\n",
      "4 0.7069706916809082\n",
      "5 0.7060105800628662\n",
      "6 0.705054521560669\n",
      "7 0.7041033506393433\n",
      "8 0.7031581401824951\n",
      "9 0.702218234539032\n",
      "10 0.701284646987915\n",
      "11 0.7003559470176697\n",
      "12 0.6994321346282959\n",
      "13 0.6985144019126892\n",
      "14 0.6976024508476257\n",
      "15 0.6966961622238159\n",
      "16 0.6957949995994568\n",
      "17 0.694898784160614\n",
      "18 0.6940069198608398\n",
      "19 0.6931210160255432\n",
      "20 0.6922411918640137\n",
      "21 0.6913670897483826\n",
      "22 0.6904979944229126\n",
      "23 0.6896365284919739\n",
      "24 0.6887794733047485\n",
      "25 0.6879273653030396\n",
      "26 0.6870818734169006\n",
      "27 0.68623948097229\n",
      "28 0.6854029893875122\n",
      "29 0.6845721006393433\n",
      "30 0.6837436556816101\n",
      "31 0.6829202771186829\n",
      "32 0.6821016073226929\n",
      "33 0.6812883019447327\n",
      "34 0.6804792881011963\n",
      "35 0.6796746253967285\n",
      "36 0.6788732409477234\n",
      "37 0.6780770421028137\n",
      "38 0.6772847175598145\n",
      "39 0.6764959096908569\n",
      "40 0.6757124066352844\n",
      "41 0.6749334335327148\n",
      "42 0.674160361289978\n",
      "43 0.6733903884887695\n",
      "44 0.6726235151290894\n",
      "45 0.6718600988388062\n",
      "46 0.6711019277572632\n",
      "47 0.670348584651947\n",
      "48 0.6695983409881592\n",
      "49 0.6688523888587952\n",
      "50 0.6681119203567505\n",
      "51 0.6673746109008789\n",
      "52 0.666641891002655\n",
      "53 0.6659133434295654\n",
      "54 0.6651883721351624\n",
      "55 0.6644667387008667\n",
      "56 0.6637490391731262\n",
      "57 0.6630345582962036\n",
      "58 0.6623241305351257\n",
      "59 0.661616325378418\n",
      "60 0.6609140634536743\n",
      "61 0.6602132320404053\n",
      "62 0.6595165133476257\n",
      "63 0.6588213443756104\n",
      "64 0.6581305265426636\n",
      "65 0.6574416160583496\n",
      "66 0.656755805015564\n",
      "67 0.6560727953910828\n",
      "68 0.6553923487663269\n",
      "69 0.654715359210968\n",
      "70 0.6540414094924927\n",
      "71 0.6533696055412292\n",
      "72 0.6527008414268494\n",
      "73 0.6520349979400635\n",
      "74 0.6513718366622925\n",
      "75 0.6507124304771423\n",
      "76 0.6500566005706787\n",
      "77 0.6494021415710449\n",
      "78 0.6487517356872559\n",
      "79 0.6481025218963623\n",
      "80 0.6474561095237732\n",
      "81 0.6468116641044617\n",
      "82 0.6461689472198486\n",
      "83 0.6455300450325012\n",
      "84 0.6448917984962463\n",
      "85 0.644256591796875\n",
      "86 0.6436247825622559\n",
      "87 0.6429935097694397\n",
      "88 0.642365574836731\n",
      "89 0.6417406797409058\n",
      "90 0.6411176919937134\n",
      "91 0.6404959559440613\n",
      "92 0.6398780345916748\n",
      "93 0.6392613649368286\n",
      "94 0.6386469602584839\n",
      "95 0.6380330324172974\n",
      "96 0.6374233961105347\n",
      "97 0.6368147134780884\n",
      "98 0.636208713054657\n",
      "99 0.6356062293052673\n",
      "100 0.6350041031837463\n",
      "101 0.6344032883644104\n",
      "102 0.6338051557540894\n",
      "103 0.633207380771637\n",
      "104 0.6326127648353577\n",
      "105 0.6320183277130127\n",
      "106 0.6314267516136169\n",
      "107 0.6308360695838928\n",
      "108 0.6302472352981567\n",
      "109 0.6296605467796326\n",
      "110 0.6290739178657532\n",
      "111 0.6284895539283752\n",
      "112 0.6279057264328003\n",
      "113 0.6273249983787537\n",
      "114 0.6267452239990234\n",
      "115 0.6261659264564514\n",
      "116 0.6255886554718018\n",
      "117 0.6250118613243103\n",
      "118 0.62443608045578\n",
      "119 0.6238617897033691\n",
      "120 0.6232879161834717\n",
      "121 0.622715413570404\n",
      "122 0.6221435070037842\n",
      "123 0.6215717196464539\n",
      "124 0.6210002303123474\n",
      "125 0.6204301714897156\n",
      "126 0.6198612451553345\n",
      "127 0.6192931532859802\n",
      "128 0.6187267899513245\n",
      "129 0.6181606650352478\n",
      "130 0.6175945401191711\n",
      "131 0.6170291304588318\n",
      "132 0.6164648532867432\n",
      "133 0.6159024238586426\n",
      "134 0.6153402924537659\n",
      "135 0.6147779822349548\n",
      "136 0.6142160296440125\n",
      "137 0.6136556267738342\n",
      "138 0.6130961775779724\n",
      "139 0.6125366687774658\n",
      "140 0.611977756023407\n",
      "141 0.6114194393157959\n",
      "142 0.6108624935150146\n",
      "143 0.6103060245513916\n",
      "144 0.6097497344017029\n",
      "145 0.6091942191123962\n",
      "146 0.6086389422416687\n",
      "147 0.6080838441848755\n",
      "148 0.6075296401977539\n",
      "149 0.6069756746292114\n",
      "150 0.6064221858978271\n",
      "151 0.6058687567710876\n",
      "152 0.605315625667572\n",
      "153 0.6047626733779907\n",
      "154 0.6042097806930542\n",
      "155 0.6036571860313416\n",
      "156 0.6031050086021423\n",
      "157 0.6025523543357849\n",
      "158 0.601999819278717\n",
      "159 0.6014472842216492\n",
      "160 0.6008949875831604\n",
      "161 0.6003420948982239\n",
      "162 0.5997893214225769\n",
      "163 0.5992371439933777\n",
      "164 0.5986838936805725\n",
      "165 0.598131000995636\n",
      "166 0.5975776314735413\n",
      "167 0.5970245003700256\n",
      "168 0.5964703559875488\n",
      "169 0.5959164500236511\n",
      "170 0.5953622460365295\n",
      "171 0.5948075652122498\n",
      "172 0.5942530632019043\n",
      "173 0.593697726726532\n",
      "174 0.5931423306465149\n",
      "175 0.5925871729850769\n",
      "176 0.592031717300415\n",
      "177 0.5914753079414368\n",
      "178 0.5909180045127869\n",
      "179 0.5903619527816772\n",
      "180 0.5898052453994751\n",
      "181 0.5892484784126282\n",
      "182 0.5886896848678589\n",
      "183 0.5881307125091553\n",
      "184 0.5875712633132935\n",
      "185 0.5870111584663391\n",
      "186 0.58645099401474\n",
      "187 0.5858900547027588\n",
      "188 0.585328996181488\n",
      "189 0.5847682356834412\n",
      "190 0.5842074155807495\n",
      "191 0.5836449265480042\n",
      "192 0.5830827355384827\n",
      "193 0.582520604133606\n",
      "194 0.5819569826126099\n",
      "195 0.5813930630683899\n",
      "196 0.5808284282684326\n",
      "197 0.5802635550498962\n",
      "198 0.5796965956687927\n",
      "199 0.5791301727294922\n",
      "200 0.5785621404647827\n",
      "201 0.5779926776885986\n",
      "202 0.5774222016334534\n",
      "203 0.5768514275550842\n",
      "204 0.5762792229652405\n",
      "205 0.575705885887146\n",
      "206 0.5751316547393799\n",
      "207 0.5745550394058228\n",
      "208 0.5739771127700806\n",
      "209 0.5733985304832458\n",
      "210 0.5728184580802917\n",
      "211 0.5722376108169556\n",
      "212 0.5716555118560791\n",
      "213 0.5710709095001221\n",
      "214 0.570486307144165\n",
      "215 0.5698999762535095\n",
      "216 0.5693129897117615\n",
      "217 0.5687242150306702\n",
      "218 0.5681337714195251\n",
      "219 0.5675422549247742\n",
      "220 0.566948652267456\n",
      "221 0.5663546919822693\n",
      "222 0.5657592415809631\n",
      "223 0.5651605725288391\n",
      "224 0.5645610690116882\n",
      "225 0.5639591813087463\n",
      "226 0.5633567571640015\n",
      "227 0.5627516508102417\n",
      "228 0.5621446371078491\n",
      "229 0.5615362524986267\n",
      "230 0.5609260201454163\n",
      "231 0.5603142380714417\n",
      "232 0.5597001314163208\n",
      "233 0.5590847134590149\n",
      "234 0.5584667921066284\n",
      "235 0.5578474998474121\n",
      "236 0.5572254061698914\n",
      "237 0.5566009879112244\n",
      "238 0.5559748411178589\n",
      "239 0.5553463101387024\n",
      "240 0.5547152757644653\n",
      "241 0.5540828704833984\n",
      "242 0.553447425365448\n",
      "243 0.5528098940849304\n",
      "244 0.55217045545578\n",
      "245 0.5515286922454834\n",
      "246 0.5508838891983032\n",
      "247 0.5502375960350037\n",
      "248 0.5495893359184265\n",
      "249 0.5489382147789001\n",
      "250 0.548285722732544\n",
      "251 0.5476309061050415\n",
      "252 0.5469738841056824\n",
      "253 0.5463142991065979\n",
      "254 0.5456531047821045\n",
      "255 0.5449895858764648\n",
      "256 0.5443239808082581\n",
      "257 0.5436558127403259\n",
      "258 0.5429844260215759\n",
      "259 0.5423112511634827\n",
      "260 0.5416355729103088\n",
      "261 0.5409579873085022\n",
      "262 0.5402763485908508\n",
      "263 0.5395933985710144\n",
      "264 0.5389078259468079\n",
      "265 0.5382202863693237\n",
      "266 0.5375304818153381\n",
      "267 0.5368377566337585\n",
      "268 0.5361426472663879\n",
      "269 0.535446286201477\n",
      "270 0.5347477197647095\n",
      "271 0.5340458750724792\n",
      "272 0.533341646194458\n",
      "273 0.5326349139213562\n",
      "274 0.53192538022995\n",
      "275 0.5312141180038452\n",
      "276 0.5304992198944092\n",
      "277 0.5297824144363403\n",
      "278 0.5290622115135193\n",
      "279 0.5283403992652893\n",
      "280 0.5276160836219788\n",
      "281 0.5268903374671936\n",
      "282 0.5261613130569458\n",
      "283 0.5254311561584473\n",
      "284 0.5246986746788025\n",
      "285 0.5239639282226562\n",
      "286 0.5232270956039429\n",
      "287 0.5224883556365967\n",
      "288 0.5217471122741699\n",
      "289 0.5210034847259521\n",
      "290 0.5202569365501404\n",
      "291 0.5195088386535645\n",
      "292 0.5187584161758423\n",
      "293 0.5180065035820007\n",
      "294 0.5172527432441711\n",
      "295 0.5164971351623535\n",
      "296 0.5157405734062195\n",
      "297 0.5149818062782288\n",
      "298 0.5142216682434082\n",
      "299 0.5134590864181519\n",
      "300 0.5126941800117493\n",
      "301 0.51192706823349\n",
      "302 0.5111594796180725\n",
      "303 0.510390043258667\n",
      "304 0.5096192955970764\n",
      "305 0.5088471174240112\n",
      "306 0.5080735087394714\n",
      "307 0.5072980523109436\n",
      "308 0.5065214037895203\n",
      "309 0.5057421326637268\n",
      "310 0.5049606561660767\n",
      "311 0.5041773319244385\n",
      "312 0.5033935904502869\n",
      "313 0.5026088356971741\n",
      "314 0.5018212795257568\n",
      "315 0.5010318160057068\n",
      "316 0.5002413988113403\n",
      "317 0.4994489252567291\n",
      "318 0.49865496158599854\n",
      "319 0.4978591203689575\n",
      "320 0.4970622658729553\n",
      "321 0.49626386165618896\n",
      "322 0.4954632818698883\n",
      "323 0.4946625232696533\n",
      "324 0.49385905265808105\n",
      "325 0.4930541515350342\n",
      "326 0.49224698543548584\n",
      "327 0.4914383590221405\n",
      "328 0.49062713980674744\n",
      "329 0.4898149073123932\n",
      "330 0.4890012741088867\n",
      "331 0.4881865680217743\n",
      "332 0.4873700439929962\n",
      "333 0.4865513741970062\n",
      "334 0.48573097586631775\n",
      "335 0.4849097728729248\n",
      "336 0.48408761620521545\n",
      "337 0.48326441645622253\n",
      "338 0.48243993520736694\n",
      "339 0.48161521553993225\n",
      "340 0.48078885674476624\n",
      "341 0.4799610674381256\n",
      "342 0.47913265228271484\n",
      "343 0.4783025085926056\n",
      "344 0.4774722456932068\n",
      "345 0.47663962841033936\n",
      "346 0.47580623626708984\n",
      "347 0.4749731421470642\n",
      "348 0.4741390645503998\n",
      "349 0.47330379486083984\n",
      "350 0.472468763589859\n",
      "351 0.47163358330726624\n",
      "352 0.47079792618751526\n",
      "353 0.46996214985847473\n",
      "354 0.4691257178783417\n",
      "355 0.46828871965408325\n",
      "356 0.4674515724182129\n",
      "357 0.4666139483451843\n",
      "358 0.46577543020248413\n",
      "359 0.46493542194366455\n",
      "360 0.4640953838825226\n",
      "361 0.4632546305656433\n",
      "362 0.46241438388824463\n",
      "363 0.46157243847846985\n",
      "364 0.4607299864292145\n",
      "365 0.4598866403102875\n",
      "366 0.4590403437614441\n",
      "367 0.45819395780563354\n",
      "368 0.45734575390815735\n",
      "369 0.45649540424346924\n",
      "370 0.4556453227996826\n",
      "371 0.45479485392570496\n",
      "372 0.4539439082145691\n",
      "373 0.45309242606163025\n",
      "374 0.4522404074668884\n",
      "375 0.45138871669769287\n",
      "376 0.45053601264953613\n",
      "377 0.44968339800834656\n",
      "378 0.4488297700881958\n",
      "379 0.447976291179657\n",
      "380 0.44712305068969727\n",
      "381 0.44626981019973755\n",
      "382 0.44541624188423157\n",
      "383 0.4445631802082062\n",
      "384 0.44371065497398376\n",
      "385 0.4428584575653076\n",
      "386 0.4420069456100464\n",
      "387 0.44115519523620605\n",
      "388 0.440304160118103\n",
      "389 0.43945279717445374\n",
      "390 0.43860185146331787\n",
      "391 0.43775084614753723\n",
      "392 0.4368998408317566\n",
      "393 0.43604862689971924\n",
      "394 0.43519797921180725\n",
      "395 0.4343474805355072\n",
      "396 0.43349769711494446\n",
      "397 0.4326483905315399\n",
      "398 0.43180063366889954\n",
      "399 0.43095192313194275\n",
      "400 0.43010413646698\n",
      "401 0.42925649881362915\n",
      "402 0.42840978503227234\n",
      "403 0.4275628626346588\n",
      "404 0.42671695351600647\n",
      "405 0.4258713126182556\n",
      "406 0.4250257611274719\n",
      "407 0.42418161034584045\n",
      "408 0.4233381748199463\n",
      "409 0.42249593138694763\n",
      "410 0.4216528534889221\n",
      "411 0.4208102822303772\n",
      "412 0.4199692904949188\n",
      "413 0.4191289246082306\n",
      "414 0.41828957200050354\n",
      "415 0.41745179891586304\n",
      "416 0.41661447286605835\n",
      "417 0.4157769978046417\n",
      "418 0.4149412214756012\n",
      "419 0.4141058325767517\n",
      "420 0.4132707118988037\n",
      "421 0.41243776679039\n",
      "422 0.41160598397254944\n",
      "423 0.4107758700847626\n",
      "424 0.4099467992782593\n",
      "425 0.40911829471588135\n",
      "426 0.4082910120487213\n",
      "427 0.40746375918388367\n",
      "428 0.406637042760849\n",
      "429 0.4058118164539337\n",
      "430 0.4049869477748871\n",
      "431 0.40416383743286133\n",
      "432 0.4033413231372833\n",
      "433 0.40251949429512024\n",
      "434 0.40169864892959595\n",
      "435 0.4008793532848358\n",
      "436 0.40006035566329956\n",
      "437 0.3992430865764618\n",
      "438 0.3984265923500061\n",
      "439 0.3976113796234131\n",
      "440 0.3967979848384857\n",
      "441 0.3959857225418091\n",
      "442 0.3951745927333832\n",
      "443 0.3943651020526886\n",
      "444 0.39355653524398804\n",
      "445 0.39274996519088745\n",
      "446 0.3919435441493988\n",
      "447 0.3911381959915161\n",
      "448 0.3903350532054901\n",
      "449 0.38953256607055664\n",
      "450 0.38873204588890076\n",
      "451 0.3879331350326538\n",
      "452 0.3871345520019531\n",
      "453 0.38633835315704346\n",
      "454 0.3855435252189636\n",
      "455 0.384750634431839\n",
      "456 0.38395920395851135\n",
      "457 0.3831680715084076\n",
      "458 0.38237863779067993\n",
      "459 0.3815898299217224\n",
      "460 0.38080164790153503\n",
      "461 0.3800143897533417\n",
      "462 0.3792288303375244\n",
      "463 0.3784453272819519\n",
      "464 0.37766265869140625\n",
      "465 0.37688159942626953\n",
      "466 0.37610161304473877\n",
      "467 0.37532204389572144\n",
      "468 0.3745444118976593\n",
      "469 0.37376874685287476\n",
      "470 0.37299469113349915\n",
      "471 0.3722214102745056\n",
      "472 0.37144935131073\n",
      "473 0.37067851424217224\n",
      "474 0.36990973353385925\n",
      "475 0.36914241313934326\n",
      "476 0.36837732791900635\n",
      "477 0.36761295795440674\n",
      "478 0.36684978008270264\n",
      "479 0.36608803272247314\n",
      "480 0.36532843112945557\n",
      "481 0.36456984281539917\n",
      "482 0.3638136684894562\n",
      "483 0.3630587160587311\n",
      "484 0.36230576038360596\n",
      "485 0.36155468225479126\n",
      "486 0.36080482602119446\n",
      "487 0.36005663871765137\n",
      "488 0.35930946469306946\n",
      "489 0.35856324434280396\n",
      "490 0.3578172028064728\n",
      "491 0.35707277059555054\n",
      "492 0.3563292324542999\n",
      "493 0.35558733344078064\n",
      "494 0.35484781861305237\n",
      "495 0.35410982370376587\n",
      "496 0.35337352752685547\n",
      "497 0.3526389002799988\n",
      "498 0.3519055247306824\n",
      "499 0.35117363929748535\n",
      "500 0.35044369101524353\n",
      "501 0.3497156500816345\n",
      "502 0.34898892045021057\n",
      "503 0.3482644557952881\n",
      "504 0.3475415110588074\n",
      "505 0.3468211591243744\n",
      "506 0.34610244631767273\n",
      "507 0.34538576006889343\n",
      "508 0.3446708917617798\n",
      "509 0.3439579904079437\n",
      "510 0.3432459831237793\n",
      "511 0.34253591299057007\n",
      "512 0.3418271839618683\n",
      "513 0.341119647026062\n",
      "514 0.3404144048690796\n",
      "515 0.3397098779678345\n",
      "516 0.3390083611011505\n",
      "517 0.3383083939552307\n",
      "518 0.3376099765300751\n",
      "519 0.3369133770465851\n",
      "520 0.33621925115585327\n",
      "521 0.3355265259742737\n",
      "522 0.33483585715293884\n",
      "523 0.33414724469184875\n",
      "524 0.3334599435329437\n",
      "525 0.332775354385376\n",
      "526 0.33209240436553955\n",
      "527 0.3314111530780792\n",
      "528 0.3307317793369293\n",
      "529 0.33005478978157043\n",
      "530 0.3293799161911011\n",
      "531 0.32870689034461975\n",
      "532 0.3280356526374817\n",
      "533 0.3273662328720093\n",
      "534 0.32669925689697266\n",
      "535 0.3260335922241211\n",
      "536 0.3253704011440277\n",
      "537 0.3247087895870209\n",
      "538 0.3240493834018707\n",
      "539 0.32339170575141907\n",
      "540 0.32273632287979126\n",
      "541 0.3220827281475067\n",
      "542 0.321430504322052\n",
      "543 0.3207811117172241\n",
      "544 0.3201334774494171\n",
      "545 0.3194881081581116\n",
      "546 0.3188444972038269\n",
      "547 0.3182029724121094\n",
      "548 0.3175637125968933\n",
      "549 0.31692594289779663\n",
      "550 0.31629008054733276\n",
      "551 0.31565722823143005\n",
      "552 0.3150258958339691\n",
      "553 0.31439638137817383\n",
      "554 0.3137691915035248\n",
      "555 0.31314367055892944\n",
      "556 0.3125196695327759\n",
      "557 0.311897337436676\n",
      "558 0.31127747893333435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559 0.3106587827205658\n",
      "560 0.3100413978099823\n",
      "561 0.3094254732131958\n",
      "562 0.3088110685348511\n",
      "563 0.30819767713546753\n",
      "564 0.3075858950614929\n",
      "565 0.3069759011268616\n",
      "566 0.306367427110672\n",
      "567 0.30576092004776\n",
      "568 0.3051562011241913\n",
      "569 0.3045528531074524\n",
      "570 0.3039519488811493\n",
      "571 0.3033520579338074\n",
      "572 0.3027542233467102\n",
      "573 0.3021581470966339\n",
      "574 0.3015638589859009\n",
      "575 0.30097052454948425\n",
      "576 0.30037859082221985\n",
      "577 0.2997884154319763\n",
      "578 0.2991999387741089\n",
      "579 0.29861316084861755\n",
      "580 0.29802826046943665\n",
      "581 0.297445684671402\n",
      "582 0.29686370491981506\n",
      "583 0.29628297686576843\n",
      "584 0.2957042157649994\n",
      "585 0.2951275706291199\n",
      "586 0.29455187916755676\n",
      "587 0.29397818446159363\n",
      "588 0.2934064269065857\n",
      "589 0.29283708333969116\n",
      "590 0.29226914048194885\n",
      "591 0.29170292615890503\n",
      "592 0.291138619184494\n",
      "593 0.29057663679122925\n",
      "594 0.2900160849094391\n",
      "595 0.28945785760879517\n",
      "596 0.2889007031917572\n",
      "597 0.2883458435535431\n",
      "598 0.2877925634384155\n",
      "599 0.28724074363708496\n",
      "600 0.28669071197509766\n",
      "601 0.2861415147781372\n",
      "602 0.2855941653251648\n",
      "603 0.2850486636161804\n",
      "604 0.2845049202442169\n",
      "605 0.283963143825531\n",
      "606 0.2834227979183197\n",
      "607 0.28288403153419495\n",
      "608 0.2823469042778015\n",
      "609 0.28181174397468567\n",
      "610 0.28127893805503845\n",
      "611 0.28074726462364197\n",
      "612 0.2802160084247589\n",
      "613 0.2796863615512848\n",
      "614 0.27915850281715393\n",
      "615 0.2786318063735962\n",
      "616 0.2781068682670593\n",
      "617 0.27758312225341797\n",
      "618 0.2770618200302124\n",
      "619 0.27654170989990234\n",
      "620 0.27602311968803406\n",
      "621 0.27550628781318665\n",
      "622 0.2749907374382019\n",
      "623 0.27447742223739624\n",
      "624 0.27396532893180847\n",
      "625 0.27345502376556396\n",
      "626 0.2729457914829254\n",
      "627 0.2724383771419525\n",
      "628 0.2719325125217438\n",
      "629 0.2714282274246216\n",
      "630 0.2709254324436188\n",
      "631 0.2704244554042816\n",
      "632 0.26992544531822205\n",
      "633 0.2694283127784729\n",
      "634 0.2689334750175476\n",
      "635 0.2684398889541626\n",
      "636 0.2679480016231537\n",
      "637 0.2674577534198761\n",
      "638 0.2669687569141388\n",
      "639 0.2664816081523895\n",
      "640 0.2659963369369507\n",
      "641 0.26551225781440735\n",
      "642 0.26502975821495056\n",
      "643 0.2645488381385803\n",
      "644 0.264069527387619\n",
      "645 0.2635917365550995\n",
      "646 0.2631155252456665\n",
      "647 0.2626407742500305\n",
      "648 0.2621671259403229\n",
      "649 0.2616952657699585\n",
      "650 0.2612247169017792\n",
      "651 0.26075565814971924\n",
      "652 0.26028791069984436\n",
      "653 0.2598218619823456\n",
      "654 0.25935783982276917\n",
      "655 0.25889450311660767\n",
      "656 0.2584330141544342\n",
      "657 0.257972776889801\n",
      "658 0.25751394033432007\n",
      "659 0.2570574879646301\n",
      "660 0.25660213828086853\n",
      "661 0.2561482787132263\n",
      "662 0.25569576025009155\n",
      "663 0.2552446722984314\n",
      "664 0.2547953426837921\n",
      "665 0.25434714555740356\n",
      "666 0.2539004981517792\n",
      "667 0.2534554898738861\n",
      "668 0.2530118525028229\n",
      "669 0.25256961584091187\n",
      "670 0.2521285116672516\n",
      "671 0.2516891062259674\n",
      "672 0.25125110149383545\n",
      "673 0.2508144974708557\n",
      "674 0.2503790557384491\n",
      "675 0.24994485080242157\n",
      "676 0.24951237440109253\n",
      "677 0.2490812987089157\n",
      "678 0.24865172803401947\n",
      "679 0.2482234537601471\n",
      "680 0.24779634177684784\n",
      "681 0.2473706603050232\n",
      "682 0.24694637954235077\n",
      "683 0.24652338027954102\n",
      "684 0.24610166251659393\n",
      "685 0.2456812858581543\n",
      "686 0.2452619969844818\n",
      "687 0.24484431743621826\n",
      "688 0.24442842602729797\n",
      "689 0.24401360750198364\n",
      "690 0.24360033869743347\n",
      "691 0.2431878298521042\n",
      "692 0.24277552962303162\n",
      "693 0.24236442148685455\n",
      "694 0.24195432662963867\n",
      "695 0.2415449619293213\n",
      "696 0.24113571643829346\n",
      "697 0.24072766304016113\n",
      "698 0.2403203397989273\n",
      "699 0.2399141639471054\n",
      "700 0.23950904607772827\n",
      "701 0.2391049712896347\n",
      "702 0.23870207369327545\n",
      "703 0.23830054700374603\n",
      "704 0.2379002422094345\n",
      "705 0.2375013679265976\n",
      "706 0.23710301518440247\n",
      "707 0.23670594394207\n",
      "708 0.236310213804245\n",
      "709 0.23591534793376923\n",
      "710 0.23552179336547852\n",
      "711 0.23512937128543854\n",
      "712 0.23473817110061646\n",
      "713 0.23434817790985107\n",
      "714 0.23395952582359314\n",
      "715 0.23357200622558594\n",
      "716 0.2331855595111847\n",
      "717 0.23280061781406403\n",
      "718 0.23241649568080902\n",
      "719 0.23203375935554504\n",
      "720 0.23165199160575867\n",
      "721 0.23127152025699615\n",
      "722 0.23089247941970825\n",
      "723 0.23051466047763824\n",
      "724 0.2301381528377533\n",
      "725 0.2297627478837967\n",
      "726 0.22938871383666992\n",
      "727 0.2290160357952118\n",
      "728 0.22864454984664917\n",
      "729 0.22827425599098206\n",
      "730 0.22790490090847015\n",
      "731 0.2275368720293045\n",
      "732 0.22716988623142242\n",
      "733 0.2268040031194687\n",
      "734 0.22643938660621643\n",
      "735 0.22607573866844177\n",
      "736 0.22571302950382233\n",
      "737 0.22535179555416107\n",
      "738 0.22499139606952667\n",
      "739 0.22463193535804749\n",
      "740 0.22427372634410858\n",
      "741 0.22391679883003235\n",
      "742 0.22356073558330536\n",
      "743 0.22320584952831268\n",
      "744 0.2228517085313797\n",
      "745 0.22249872982501984\n",
      "746 0.2221469134092331\n",
      "747 0.22179625928401947\n",
      "748 0.22144652903079987\n",
      "749 0.22109772264957428\n",
      "750 0.22075031697750092\n",
      "751 0.22040405869483948\n",
      "752 0.22005854547023773\n",
      "753 0.21971404552459717\n",
      "754 0.2193705439567566\n",
      "755 0.21902835369110107\n",
      "756 0.21868719160556793\n",
      "757 0.2183469980955124\n",
      "758 0.21800796687602997\n",
      "759 0.21767006814479828\n",
      "760 0.21733345091342926\n",
      "761 0.21699748933315277\n",
      "762 0.2166626900434494\n",
      "763 0.216328963637352\n",
      "764 0.21599653363227844\n",
      "765 0.21566465497016907\n",
      "766 0.21533408761024475\n",
      "767 0.2150043249130249\n",
      "768 0.2146754413843155\n",
      "769 0.21434767544269562\n",
      "770 0.21402068436145782\n",
      "771 0.21369491517543793\n",
      "772 0.2133699655532837\n",
      "773 0.21304580569267273\n",
      "774 0.2127227783203125\n",
      "775 0.21240079402923584\n",
      "776 0.21207989752292633\n",
      "777 0.21175993978977203\n",
      "778 0.21144074201583862\n",
      "779 0.2111225426197052\n",
      "780 0.21080522239208221\n",
      "781 0.21048901975154877\n",
      "782 0.2101738452911377\n",
      "783 0.20985957980155945\n",
      "784 0.20954616367816925\n",
      "785 0.2092335969209671\n",
      "786 0.20892225205898285\n",
      "787 0.20861183106899261\n",
      "788 0.20830217003822327\n",
      "789 0.20799382030963898\n",
      "790 0.2076859474182129\n",
      "791 0.20737916231155396\n",
      "792 0.20707325637340546\n",
      "793 0.20676806569099426\n",
      "794 0.20646409690380096\n",
      "795 0.2061610072851181\n",
      "796 0.2058587670326233\n",
      "797 0.2055574506521225\n",
      "798 0.2052570879459381\n",
      "799 0.204957515001297\n",
      "800 0.20465902984142303\n",
      "801 0.20436108112335205\n",
      "802 0.2040639966726303\n",
      "803 0.2037680447101593\n",
      "804 0.2034727931022644\n",
      "805 0.20317836105823517\n",
      "806 0.20288455486297607\n",
      "807 0.20259198546409607\n",
      "808 0.2022998183965683\n",
      "809 0.20200864970684052\n",
      "810 0.20171838998794556\n",
      "811 0.20142918825149536\n",
      "812 0.2011406272649765\n",
      "813 0.2008528858423233\n",
      "814 0.2005661427974701\n",
      "815 0.20027992129325867\n",
      "816 0.19999466836452484\n",
      "817 0.19971030950546265\n",
      "818 0.1994265913963318\n",
      "819 0.19914361834526062\n",
      "820 0.19886165857315063\n",
      "821 0.19858036935329437\n",
      "822 0.19829976558685303\n",
      "823 0.19802045822143555\n",
      "824 0.19774185121059418\n",
      "825 0.1974639892578125\n",
      "826 0.19718678295612335\n",
      "827 0.19691070914268494\n",
      "828 0.19663502275943756\n",
      "829 0.19636040925979614\n",
      "830 0.19608642160892487\n",
      "831 0.19581325352191925\n",
      "832 0.1955406814813614\n",
      "833 0.19526919722557068\n",
      "834 0.19499801099300385\n",
      "835 0.19472791254520416\n",
      "836 0.19445854425430298\n",
      "837 0.1941898912191391\n",
      "838 0.1939220130443573\n",
      "839 0.19365496933460236\n",
      "840 0.19338834285736084\n",
      "841 0.1931229829788208\n",
      "842 0.1928580105304718\n",
      "843 0.19259363412857056\n",
      "844 0.19233013689517975\n",
      "845 0.19206741452217102\n",
      "846 0.19180551171302795\n",
      "847 0.19154420495033264\n",
      "848 0.19128361344337463\n",
      "849 0.19102375209331512\n",
      "850 0.19076435267925262\n",
      "851 0.1905059516429901\n",
      "852 0.1902480125427246\n",
      "853 0.1899910420179367\n",
      "854 0.1897345781326294\n",
      "855 0.18947897851467133\n",
      "856 0.18922416865825653\n",
      "857 0.1889699101448059\n",
      "858 0.18871621787548065\n",
      "859 0.18846331536769867\n",
      "860 0.1882110834121704\n",
      "861 0.18795950710773468\n",
      "862 0.18770870566368103\n",
      "863 0.18745851516723633\n",
      "864 0.18720902502536774\n",
      "865 0.18696007132530212\n",
      "866 0.18671193718910217\n",
      "867 0.18646445870399475\n",
      "868 0.1862175017595291\n",
      "869 0.1859714388847351\n",
      "870 0.1857258826494217\n",
      "871 0.18548087775707245\n",
      "872 0.18523678183555603\n",
      "873 0.18499305844306946\n",
      "874 0.18475016951560974\n",
      "875 0.18450778722763062\n",
      "876 0.1842661201953888\n",
      "877 0.18402516841888428\n",
      "878 0.18378475308418274\n",
      "879 0.18354487419128418\n",
      "880 0.1833060085773468\n",
      "881 0.1830676794052124\n",
      "882 0.18283003568649292\n",
      "883 0.18259303271770477\n",
      "884 0.18235650658607483\n",
      "885 0.18212062120437622\n",
      "886 0.18188536167144775\n",
      "887 0.18165098130702972\n",
      "888 0.18141689896583557\n",
      "889 0.18118369579315186\n",
      "890 0.18095088005065918\n",
      "891 0.18071889877319336\n",
      "892 0.18048742413520813\n",
      "893 0.18025648593902588\n",
      "894 0.1800261288881302\n",
      "895 0.17979654669761658\n",
      "896 0.17956756055355072\n",
      "897 0.17933908104896545\n",
      "898 0.17911158502101898\n",
      "899 0.1788845956325531\n",
      "900 0.1786581128835678\n",
      "901 0.17843225598335266\n",
      "902 0.17820695042610168\n",
      "903 0.1779821366071701\n",
      "904 0.17775806784629822\n",
      "905 0.17753472924232483\n",
      "906 0.1773120015859604\n",
      "907 0.1770896166563034\n",
      "908 0.17686788737773895\n",
      "909 0.1766471266746521\n",
      "910 0.17642705142498016\n",
      "911 0.17620749771595\n",
      "912 0.17598843574523926\n",
      "913 0.17576994001865387\n",
      "914 0.17555224895477295\n",
      "915 0.17533531785011292\n",
      "916 0.17511877417564392\n",
      "917 0.17490293085575104\n",
      "918 0.17468775808811188\n",
      "919 0.17447280883789062\n",
      "920 0.1742587834596634\n",
      "921 0.17404530942440033\n",
      "922 0.17383235692977905\n",
      "923 0.17361994087696075\n",
      "924 0.17340806126594543\n",
      "925 0.17319686710834503\n",
      "926 0.1729860156774521\n",
      "927 0.17277580499649048\n",
      "928 0.17256617546081543\n",
      "929 0.17235733568668365\n",
      "930 0.1721484214067459\n",
      "931 0.1719406247138977\n",
      "932 0.1717330813407898\n",
      "933 0.17152616381645203\n",
      "934 0.17131999135017395\n",
      "935 0.1711140275001526\n",
      "936 0.1709088236093521\n",
      "937 0.1707039773464203\n",
      "938 0.17049983143806458\n",
      "939 0.17029604315757751\n",
      "940 0.17009298503398895\n",
      "941 0.16989022493362427\n",
      "942 0.16968804597854614\n",
      "943 0.1694864183664322\n",
      "944 0.16928519308567047\n",
      "945 0.16908453404903412\n",
      "946 0.16888445615768433\n",
      "947 0.16868487000465393\n",
      "948 0.16848576068878174\n",
      "949 0.16828717291355133\n",
      "950 0.16808900237083435\n",
      "951 0.16789138317108154\n",
      "952 0.16769415140151978\n",
      "953 0.16749761998653412\n",
      "954 0.1673015058040619\n",
      "955 0.1671057939529419\n",
      "956 0.1669105887413025\n",
      "957 0.16671578586101532\n",
      "958 0.1665220409631729\n",
      "959 0.16632819175720215\n",
      "960 0.1661347895860672\n",
      "961 0.1659422516822815\n",
      "962 0.16575004160404205\n",
      "963 0.16555826365947723\n",
      "964 0.1653670221567154\n",
      "965 0.1651761531829834\n",
      "966 0.16498611867427826\n",
      "967 0.16479641199111938\n",
      "968 0.16460713744163513\n",
      "969 0.16441844403743744\n",
      "970 0.16423001885414124\n",
      "971 0.16404218971729279\n",
      "972 0.163854718208313\n",
      "973 0.16366782784461975\n",
      "974 0.16348136961460114\n",
      "975 0.16329523921012878\n",
      "976 0.16310974955558777\n",
      "977 0.16292482614517212\n",
      "978 0.16274014115333557\n",
      "979 0.16255611181259155\n",
      "980 0.16237252950668335\n",
      "981 0.16218914091587067\n",
      "982 0.16200658679008484\n",
      "983 0.16182434558868408\n",
      "984 0.1616424173116684\n",
      "985 0.1614609956741333\n",
      "986 0.16128012537956238\n",
      "987 0.16109973192214966\n",
      "988 0.16091975569725037\n",
      "989 0.16074004769325256\n",
      "990 0.16056086122989655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991 0.16038228571414948\n",
      "992 0.1602039486169815\n",
      "993 0.16002614796161652\n",
      "994 0.15984871983528137\n",
      "995 0.15967172384262085\n",
      "996 0.15949523448944092\n",
      "997 0.15931902825832367\n",
      "998 0.15914317965507507\n",
      "999 0.1589680165052414\n"
     ]
    }
   ],
   "source": [
    "for t in range(1000):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建测试样例并进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0471,  1.6578],\n",
       "        [ 0.1347, -0.9502],\n",
       "        [-0.3595, -0.0066],\n",
       "        [-0.6453,  0.6148],\n",
       "        [-0.7034, -0.3515],\n",
       "        [ 0.1038, -0.9994],\n",
       "        [-0.6848,  0.2726],\n",
       "        [ 0.4836, -0.3850],\n",
       "        [-0.1286, -0.7618],\n",
       "        [ 0.8934, -1.2505],\n",
       "        [ 1.0801, -0.9338],\n",
       "        [-0.6263,  0.3724],\n",
       "        [-0.2332,  0.6058],\n",
       "        [ 0.3896,  0.5382],\n",
       "        [-0.0737, -0.3575],\n",
       "        [ 0.6664, -1.6678],\n",
       "        [ 0.5274,  1.2645],\n",
       "        [-0.1033,  1.2831],\n",
       "        [-0.1164,  0.4905],\n",
       "        [ 3.0742, -0.1289],\n",
       "        [ 2.0041, -0.0471],\n",
       "        [ 0.4675, -0.7753],\n",
       "        [ 1.3200,  0.2209],\n",
       "        [-0.8295,  0.4261],\n",
       "        [-1.2080, -0.8760],\n",
       "        [-0.6799,  0.7134],\n",
       "        [-1.7716, -0.0638],\n",
       "        [ 1.3408,  2.0215],\n",
       "        [-0.3532,  0.6015],\n",
       "        [-0.9768,  0.0186],\n",
       "        [-0.0430, -0.2725],\n",
       "        [ 0.5445, -0.4543],\n",
       "        [ 1.1438, -0.1236],\n",
       "        [ 1.9100,  1.2751],\n",
       "        [-1.1048,  0.9017],\n",
       "        [-0.9528,  0.8442],\n",
       "        [ 1.0071, -1.3320],\n",
       "        [-0.7356, -1.5842],\n",
       "        [-0.9313, -3.1176],\n",
       "        [-1.6362,  0.8185],\n",
       "        [ 0.2622,  0.2297],\n",
       "        [ 0.6122,  0.3136],\n",
       "        [-0.2608, -1.4562],\n",
       "        [ 0.2054, -2.0694],\n",
       "        [ 0.4546,  1.1793],\n",
       "        [ 0.4232,  1.9480],\n",
       "        [ 0.3558,  0.0922],\n",
       "        [-1.1746, -1.2872],\n",
       "        [ 1.4303, -0.2222],\n",
       "        [-0.8716, -0.3930],\n",
       "        [ 0.1208,  1.7724],\n",
       "        [-1.1118,  0.6983],\n",
       "        [-1.0924, -1.7955],\n",
       "        [-0.8985, -0.2029],\n",
       "        [ 2.0697, -0.5741],\n",
       "        [ 0.4069,  0.7171],\n",
       "        [-1.7286,  1.0278],\n",
       "        [ 0.6525,  0.0885],\n",
       "        [-0.4862, -0.4655],\n",
       "        [ 0.9262,  0.3870],\n",
       "        [ 0.6573,  1.1380],\n",
       "        [-0.5690, -0.7241],\n",
       "        [-0.8368, -0.1438],\n",
       "        [ 0.1790,  0.6192],\n",
       "        [ 0.2096, -0.3343],\n",
       "        [-0.5760,  0.3067],\n",
       "        [ 0.0257,  0.6535],\n",
       "        [-0.5380, -0.1502],\n",
       "        [-1.5342, -0.7585],\n",
       "        [-0.3725,  0.6837],\n",
       "        [-0.0827,  0.3892],\n",
       "        [ 0.4247, -1.2566],\n",
       "        [-0.1917,  2.7196],\n",
       "        [-1.2375,  1.8227],\n",
       "        [-0.4068,  0.3892],\n",
       "        [-1.0380,  0.6493],\n",
       "        [ 0.7595, -0.9905],\n",
       "        [-0.2882, -0.1444],\n",
       "        [-1.1722,  0.9094],\n",
       "        [ 0.0671,  1.5595],\n",
       "        [-0.9572,  2.6705],\n",
       "        [-0.0727, -1.3407],\n",
       "        [-0.0962, -1.9234],\n",
       "        [-0.4914, -0.4935],\n",
       "        [-0.0128, -1.4317],\n",
       "        [-2.2341,  1.3293],\n",
       "        [ 0.8606, -0.4159],\n",
       "        [-0.1888,  0.1137],\n",
       "        [-0.6652, -0.1336],\n",
       "        [ 0.7801,  0.0862],\n",
       "        [ 0.7747, -0.4345],\n",
       "        [ 0.1080, -0.3515],\n",
       "        [ 0.4617, -0.7625],\n",
       "        [-1.0766, -1.0373],\n",
       "        [-1.6517, -0.7745],\n",
       "        [-0.2056, -0.8037],\n",
       "        [-0.7404,  0.3994],\n",
       "        [-0.4014,  0.8538],\n",
       "        [-1.7724,  1.1704],\n",
       "        [-0.9767,  0.3049]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = torch.randn(100, 2)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = torch.zeros(100, 1)\n",
    "y_test[torch.sum(x_test, dim=1) >= 0] = 1\n",
    "# y_test[x_test.sum(dim=1) >= 0] = 1\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = torch.zeros(100, 1)\n",
    "y_test_pred[model(x_test) >= .5] = 1\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurate: 0.99\n"
     ]
    }
   ],
   "source": [
    "result = torch.zeros(100, 1)\n",
    "result[y_test == y_test_pred] = 1\n",
    "print('accurate: {}'.format(result.sum().item() / 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存和加载模型\n",
    "### 仅保存和加载模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight', tensor([[ 1.3685,  1.2031],\n",
       "                      [-1.2733, -1.1584],\n",
       "                      [ 0.1816,  0.3188],\n",
       "                      [-0.0084,  0.1878]])),\n",
       "             ('linear1.bias', tensor([ 0.7925,  0.8872, -0.5934, -0.4613])),\n",
       "             ('linear2.weight',\n",
       "              tensor([[ 0.9867, -1.3702, -0.0533, -0.1961]])),\n",
       "             ('linear2.bias', tensor([0.3543]))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'only_parameters.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight', tensor([[ 1.3685,  1.2031],\n",
       "                      [-1.2733, -1.1584],\n",
       "                      [ 0.1816,  0.3188],\n",
       "                      [-0.0084,  0.1878]])),\n",
       "             ('linear1.bias', tensor([ 0.7925,  0.8872, -0.5934, -0.4613])),\n",
       "             ('linear2.weight',\n",
       "              tensor([[ 0.9867, -1.3702, -0.0533, -0.1961]])),\n",
       "             ('linear2.bias', tensor([0.3543]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = TwoLayerNet(2, 4, 1)\n",
    "model2.load_state_dict(torch.load('only_parameters.pt'))\n",
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurate: 0.99\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = torch.zeros(100, 1)\n",
    "y_test_pred[model2(x_test) >= .5] = 1\n",
    "result = torch.zeros(100, 1)\n",
    "result[y_test == y_test_pred] = 1\n",
    "print('accurate: {}'.format(result.sum().item() / 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存和加载整个模型\n",
    "#### 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arsener\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type TwoLayerNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'whole_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight', tensor([[ 1.3685,  1.2031],\n",
       "                      [-1.2733, -1.1584],\n",
       "                      [ 0.1816,  0.3188],\n",
       "                      [-0.0084,  0.1878]])),\n",
       "             ('linear1.bias', tensor([ 0.7925,  0.8872, -0.5934, -0.4613])),\n",
       "             ('linear2.weight',\n",
       "              tensor([[ 0.9867, -1.3702, -0.0533, -0.1961]])),\n",
       "             ('linear2.bias', tensor([0.3543]))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = torch.load('whole_model.pt')\n",
    "model3.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurate: 0.99\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = torch.zeros(100, 1)\n",
    "y_test_pred[model3(x_test) >= .5] = 1\n",
    "result = torch.zeros(100, 1)\n",
    "result[y_test == y_test_pred] = 1\n",
    "print('accurate: {}'.format(result.sum().item() / 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
