{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立一个CNN对花朵图片进行分类\n",
    "本例中使用了``torchvision.datasets.ImageFolder``以及``torch.utils.data.DataLoader``，根据本地图片文件生成训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..', 'data')\n",
    "flower_dir = os.path.join(data_dir, 'flower_photos')\n",
    "train_dir = os.path.join(flower_dir, 'train')\n",
    "test_dir = os.path.join(flower_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transforms, ImageFolder, DataLoader\n",
    "* 使用``torchvision.transforms.Compose``定义一些Data augmentation操作\n",
    "* 首先使用``torchvision.datasets.ImageFolder``读取出图片数据，之后传入transforms操作，对图片进行处理\n",
    "* 使用``torch.utils.data.DataLoader``定义Dataloader\n",
    "\n",
    "### transforms.ToTensor()\n",
    "将PIL Image或者 ndarray 转换为tensor，并且归一化至$[0-1]$\n",
    "* 注意事项：归一化至$[0-1]$是直接除以255，若自己的ndarray数据尺度有变化，则需要自行修改。\n",
    "\n",
    "### transforms.RandomRotation(degrees, resample=False, expand=False, center=None)\n",
    "依degrees随机旋转一定角度\n",
    "\n",
    "参数：\n",
    "* ``degress``- (sequence or float or int) ，若为单个数，如 30，则表示在（-30，+30）之间随机旋转\n",
    "若为sequence，如(30，60)，则表示在30-60度之间随机旋转\n",
    "* ``resample``- 重采样方法选择，可选 PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC，默认为最近邻\n",
    "* ``expand``- Optional expansion flag. If true, expands the output to make it large enough to hold the entire rotated image. If false or omitted, make the output image the same size as the input image. Note that the expand flag assumes rotation around the center and no translation.\n",
    "* ``center``- 可选为中心旋转还是左上角旋转。Default is the center of the image.\n",
    "\n",
    "**需要注意，``transforms.Resize(size)``如果只传入一个int，则会将尺寸为(height, width)的图片变为(size * height / width, size)(height > width)。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224\n",
    "batch_size = 64\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "#         transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets = {x: ImageFolder(os.path.join(flower_dir, x), data_transforms[x]) for x in [\"train\", \"val\"]}\n",
    "\n",
    "train_loader, test_loader = [torch.utils.data.DataLoader(image_datasets[x], \n",
    "        batch_size=batch_size, shuffle=True, num_workers=4) for x in [\"train\", \"val\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义一个比较简单的多层卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, padding=1)  # 224 * 224\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 24, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(24, 10, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(10 * 14 * 14, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))  # 112 * 112\n",
    "        x = self.pool(self.relu(self.conv2(x)))  # 56 * 56\n",
    "        x = self.pool(self.relu(self.conv3(x)))  # 28 * 28\n",
    "        x = self.pool(self.relu(self.conv4(x)))  # 14 * 14\n",
    "        x = x.view(-1, 10 * 14 * 14)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#nn.CrossEntropyLoss()中已包含softmax激活运算\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\n",
      "Train: Loss: 1.5872, accuracy: 0.2426 Test: Loss: 1.5444, accuracy: 0.2762\n",
      "Train Epoch: 1\n",
      "Train: Loss: 1.4645, accuracy: 0.3199 Test: Loss: 1.4020, accuracy: 0.3769\n",
      "Train Epoch: 2\n",
      "Train: Loss: 1.3272, accuracy: 0.4157 Test: Loss: 1.2645, accuracy: 0.4259\n",
      "Train Epoch: 3\n",
      "Train: Loss: 1.2146, accuracy: 0.4845 Test: Loss: 1.2075, accuracy: 0.5007\n",
      "Train Epoch: 4\n",
      "Train: Loss: 1.1525, accuracy: 0.5172 Test: Loss: 1.2079, accuracy: 0.4517\n",
      "Train Epoch: 5\n",
      "Train: Loss: 1.1461, accuracy: 0.5227 Test: Loss: 1.1160, accuracy: 0.5388\n",
      "Train Epoch: 6\n",
      "Train: Loss: 1.1159, accuracy: 0.5237 Test: Loss: 1.0781, accuracy: 0.5578\n",
      "Train Epoch: 7\n",
      "Train: Loss: 1.0967, accuracy: 0.5390 Test: Loss: 1.0513, accuracy: 0.5782\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(8):  # loop over the dataset multiple times\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_loss = 0.\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        value_pred, label_pred = torch.max(outputs, axis=1)\n",
    "        train_correct += (labels == label_pred).sum().item()\n",
    "        train_total += labels.shape[0]\n",
    "        train_loss += loss.item() * labels.shape[0]\n",
    "\n",
    "    train_loss /= train_total\n",
    "    train_correct /= train_total\n",
    "\n",
    "    # print statistics\n",
    "    print('Train Epoch: %d\\nTrain: Loss: %.4f, accuracy: %.4f ' % (epoch, train_loss, train_correct), end='')\n",
    "\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    test_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            y_pred = net(images)\n",
    "            value_pred, label_pred = torch.max(y_pred, axis=1)\n",
    "            test_correct += (labels == label_pred).sum().item()\n",
    "            test_total += labels.shape[0]\n",
    "            loss_batch = criterion(y_pred, labels)\n",
    "            test_loss += loss_batch.item() * labels.shape[0]\n",
    "\n",
    "        test_loss /= test_total\n",
    "        test_correct /= test_total\n",
    "        print('Test: Loss: %.4f, accuracy: %.4f' % (test_loss, test_correct))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0512882404586896, accuracy: 0.5782312925170068\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "loss = 0.\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        y_pred = net(images)\n",
    "        value_pred, label_pred = torch.max(y_pred, axis=1)\n",
    "        correct += (labels == label_pred).sum().item()\n",
    "        total += labels.shape[0]\n",
    "        loss_batch = criterion(y_pred, labels)\n",
    "        loss += loss_batch.item() * labels.shape[0]\n",
    "    \n",
    "    loss /= total\n",
    "    correct /= total\n",
    "    print('Loss: {}, accuracy: {}'.format(loss, correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
